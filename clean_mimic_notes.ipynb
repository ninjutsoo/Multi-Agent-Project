{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install torch transformers pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54332122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "file_path = \"/home/hq6375/Desktop/Code/MIMIC-III/physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Display dataset info\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter relevant note categories\n",
    "RELEVANT_CATEGORIES = [\"Nursing\", \"Nursing/other\", \"Social Work\"]\n",
    "df = df[df[\"CATEGORY\"].isin(RELEVANT_CATEGORIES)]\n",
    "\n",
    "# Drop missing text values\n",
    "df = df.dropna(subset=[\"TEXT\"])\n",
    "\n",
    "# Display updated dataset info\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb766ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\n+\", \" \", text)  # Remove new lines\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r\"[^\\w\\s.,]\", \"\", text)  # Remove special characters except punctuation\n",
    "    return text.lower()  # Convert to lowercase\n",
    "\n",
    "# Apply cleaning function\n",
    "df[\"CLEANED_TEXT\"] = df[\"TEXT\"].apply(clean_text)\n",
    "\n",
    "# Display cleaned text samples\n",
    "df[[\"CATEGORY\", \"CLEANED_TEXT\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432838cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_information(note):\n",
    "    instruction = \"\"\"Extract information relevant to hospital readmission:\n",
    "    1. Past hospitalizations mentioned.\n",
    "    2. Medications prescribed at discharge.\n",
    "    3. Symptoms & conditions at discharge.\n",
    "    4. Follow-up instructions and care plans.\n",
    "    Provide a structured JSON output.\"\"\"\n",
    "\n",
    "    input_text = f\"{instruction}\\n\\n{note}\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=512)\n",
    "    \n",
    "    extracted_info = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return extracted_info\n",
    "\n",
    "print(\"Function for extraction is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f037569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply extraction on a sample (100 notes for monitoring)\n",
    "df[\"EXTRACTED_INFO\"] = df[\"CLEANED_TEXT\"].sample(100).apply(extract_information)\n",
    "\n",
    "# Display extracted information\n",
    "df[[\"CATEGORY\", \"EXTRACTED_INFO\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d183f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save cleaned & extracted data\n",
    "output_path = \"/home/hq6375/Desktop/Code/MIMIC-III/processed_notes.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
